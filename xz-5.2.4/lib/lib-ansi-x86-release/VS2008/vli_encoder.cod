; Listing generated by Microsoft (R) Optimizing Compiler Version 15.00.30729.01 

	TITLE	d:\SDK\C\Library\Algorithms\Information theory and signal processing\Coding theory\Lossless compression algorithms\Dictionary coders\Lempel?Ziv\Lempel?Ziv?Markov chain (LZMA)\xz\src\c89\liblzma\common\vli_encoder.c
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB OLDNAMES

PUBLIC	_lzma_vli_encode
EXTRN	__aullshr:PROC
; Function compile flags: /Odtp
; File d:\sdk\c\library\algorithms\information theory and signal processing\coding theory\lossless compression algorithms\dictionary coders\lempel–ziv\lempel–ziv–markov chain (lzma)\xz\src\c89\liblzma\common\vli_encoder.c
;	COMDAT _lzma_vli_encode
_TEXT	SEGMENT
_vli_pos_internal$ = -4					; size = 4
_vli$ = 8						; size = 8
_vli_pos$ = 16						; size = 4
_out$ = 20						; size = 4
_out_pos$ = 24						; size = 4
_out_size$ = 28						; size = 4
_lzma_vli_encode PROC					; COMDAT

; 20   : {

  00000	55		 push	 ebp
  00001	8b ec		 mov	 ebp, esp
  00003	51		 push	 ecx

; 21   : 	// If we haven't been given vli_pos, work in single-call mode.
; 22   : 	size_t vli_pos_internal = 0;

  00004	c7 45 fc 00 00
	00 00		 mov	 DWORD PTR _vli_pos_internal$[ebp], 0

; 23   : 	if (vli_pos == NULL) {

  0000b	83 7d 10 00	 cmp	 DWORD PTR _vli_pos$[ebp], 0
  0000f	75 1c		 jne	 SHORT $LN9@lzma_vli_e

; 24   : 		vli_pos = &vli_pos_internal;

  00011	8d 45 fc	 lea	 eax, DWORD PTR _vli_pos_internal$[ebp]
  00014	89 45 10	 mov	 DWORD PTR _vli_pos$[ebp], eax

; 25   : 
; 26   : 		// In single-call mode, we expect that the caller has
; 27   : 		// reserved enough output space.
; 28   : 		if (*out_pos >= out_size)

  00017	8b 4d 18	 mov	 ecx, DWORD PTR _out_pos$[ebp]
  0001a	8b 11		 mov	 edx, DWORD PTR [ecx]
  0001c	3b 55 1c	 cmp	 edx, DWORD PTR _out_size$[ebp]
  0001f	72 0a		 jb	 SHORT $LN8@lzma_vli_e

; 29   : 			return LZMA_PROG_ERROR;

  00021	b8 0b 00 00 00	 mov	 eax, 11			; 0000000bH
  00026	e9 fa 00 00 00	 jmp	 $LN10@lzma_vli_e
$LN8@lzma_vli_e:

; 30   : 	} else {

  0002b	eb 14		 jmp	 SHORT $LN7@lzma_vli_e
$LN9@lzma_vli_e:

; 31   : 		// This never happens when we are called by liblzma, but
; 32   : 		// may happen if called directly from an application.
; 33   : 		if (*out_pos >= out_size)

  0002d	8b 45 18	 mov	 eax, DWORD PTR _out_pos$[ebp]
  00030	8b 08		 mov	 ecx, DWORD PTR [eax]
  00032	3b 4d 1c	 cmp	 ecx, DWORD PTR _out_size$[ebp]
  00035	72 0a		 jb	 SHORT $LN7@lzma_vli_e

; 34   : 			return LZMA_BUF_ERROR;

  00037	b8 0a 00 00 00	 mov	 eax, 10			; 0000000aH
  0003c	e9 e4 00 00 00	 jmp	 $LN10@lzma_vli_e
$LN7@lzma_vli_e:

; 35   : 	}
; 36   : 
; 37   : 	// Validate the arguments.
; 38   : 	if (*vli_pos >= LZMA_VLI_BYTES_MAX || vli > LZMA_VLI_MAX)

  00041	8b 55 10	 mov	 edx, DWORD PTR _vli_pos$[ebp]
  00044	83 3a 09	 cmp	 DWORD PTR [edx], 9
  00047	73 11		 jae	 SHORT $LN4@lzma_vli_e
  00049	81 7d 0c ff ff
	ff 7f		 cmp	 DWORD PTR _vli$[ebp+4], 2147483647 ; 7fffffffH
  00050	72 12		 jb	 SHORT $LN5@lzma_vli_e
  00052	77 06		 ja	 SHORT $LN4@lzma_vli_e
  00054	83 7d 08 ff	 cmp	 DWORD PTR _vli$[ebp], -1
  00058	76 0a		 jbe	 SHORT $LN5@lzma_vli_e
$LN4@lzma_vli_e:

; 39   : 		return LZMA_PROG_ERROR;

  0005a	b8 0b 00 00 00	 mov	 eax, 11			; 0000000bH
  0005f	e9 c1 00 00 00	 jmp	 $LN10@lzma_vli_e
$LN5@lzma_vli_e:

; 40   : 
; 41   : 	// Shift vli so that the next bits to encode are the lowest. In
; 42   : 	// single-call mode this never changes vli since *vli_pos is zero.
; 43   : 	vli >>= *vli_pos * 7;

  00064	8b 45 10	 mov	 eax, DWORD PTR _vli_pos$[ebp]
  00067	8b 08		 mov	 ecx, DWORD PTR [eax]
  00069	6b c9 07	 imul	 ecx, 7
  0006c	8b 45 08	 mov	 eax, DWORD PTR _vli$[ebp]
  0006f	8b 55 0c	 mov	 edx, DWORD PTR _vli$[ebp+4]
  00072	e8 00 00 00 00	 call	 __aullshr
  00077	89 45 08	 mov	 DWORD PTR _vli$[ebp], eax
  0007a	89 55 0c	 mov	 DWORD PTR _vli$[ebp+4], edx
$LN3@lzma_vli_e:

; 44   : 
; 45   : 	// Write the non-last bytes in a loop.
; 46   : 	while (vli >= 0x80) {

  0007d	83 7d 0c 00	 cmp	 DWORD PTR _vli$[ebp+4], 0
  00081	77 09		 ja	 SHORT $LN13@lzma_vli_e
  00083	81 7d 08 80 00
	00 00		 cmp	 DWORD PTR _vli$[ebp], 128 ; 00000080H
  0008a	72 62		 jb	 SHORT $LN2@lzma_vli_e
$LN13@lzma_vli_e:

; 47   : 		// We don't need *vli_pos during this function call anymore,
; 48   : 		// but update it here so that it is ready if we need to
; 49   : 		// return before the whole integer has been decoded.
; 50   : 		++*vli_pos;

  0008c	8b 4d 10	 mov	 ecx, DWORD PTR _vli_pos$[ebp]
  0008f	8b 11		 mov	 edx, DWORD PTR [ecx]
  00091	83 c2 01	 add	 edx, 1
  00094	8b 45 10	 mov	 eax, DWORD PTR _vli_pos$[ebp]
  00097	89 10		 mov	 DWORD PTR [eax], edx

; 51   : 		assert(*vli_pos < LZMA_VLI_BYTES_MAX);
; 52   : 
; 53   : 		// Write the next byte.
; 54   : 		out[*out_pos] = (uint8_t)(vli) | 0x80;

  00099	0f b6 4d 08	 movzx	 ecx, BYTE PTR _vli$[ebp]
  0009d	81 c9 80 00 00
	00		 or	 ecx, 128		; 00000080H
  000a3	8b 55 18	 mov	 edx, DWORD PTR _out_pos$[ebp]
  000a6	8b 02		 mov	 eax, DWORD PTR [edx]
  000a8	8b 55 14	 mov	 edx, DWORD PTR _out$[ebp]
  000ab	88 0c 02	 mov	 BYTE PTR [edx+eax], cl

; 55   : 		vli >>= 7;

  000ae	8b 45 08	 mov	 eax, DWORD PTR _vli$[ebp]
  000b1	8b 55 0c	 mov	 edx, DWORD PTR _vli$[ebp+4]
  000b4	b1 07		 mov	 cl, 7
  000b6	e8 00 00 00 00	 call	 __aullshr
  000bb	89 45 08	 mov	 DWORD PTR _vli$[ebp], eax
  000be	89 55 0c	 mov	 DWORD PTR _vli$[ebp+4], edx

; 56   : 
; 57   : 		if (++*out_pos == out_size)

  000c1	8b 45 18	 mov	 eax, DWORD PTR _out_pos$[ebp]
  000c4	8b 08		 mov	 ecx, DWORD PTR [eax]
  000c6	83 c1 01	 add	 ecx, 1
  000c9	8b 55 18	 mov	 edx, DWORD PTR _out_pos$[ebp]
  000cc	89 0a		 mov	 DWORD PTR [edx], ecx
  000ce	8b 45 18	 mov	 eax, DWORD PTR _out_pos$[ebp]
  000d1	8b 08		 mov	 ecx, DWORD PTR [eax]
  000d3	3b 4d 1c	 cmp	 ecx, DWORD PTR _out_size$[ebp]
  000d6	75 14		 jne	 SHORT $LN1@lzma_vli_e

; 58   : 			return vli_pos == &vli_pos_internal
; 59   : 					? LZMA_PROG_ERROR : LZMA_OK;

  000d8	8b 45 10	 mov	 eax, DWORD PTR _vli_pos$[ebp]
  000db	8d 55 fc	 lea	 edx, DWORD PTR _vli_pos_internal$[ebp]
  000de	2b c2		 sub	 eax, edx
  000e0	f7 d8		 neg	 eax
  000e2	1b c0		 sbb	 eax, eax
  000e4	83 e0 f5	 and	 eax, -11		; fffffff5H
  000e7	83 c0 0b	 add	 eax, 11			; 0000000bH
  000ea	eb 39		 jmp	 SHORT $LN10@lzma_vli_e
$LN1@lzma_vli_e:

; 60   : 	}

  000ec	eb 8f		 jmp	 SHORT $LN3@lzma_vli_e
$LN2@lzma_vli_e:

; 61   : 
; 62   : 	// Write the last byte.
; 63   : 	out[*out_pos] = (uint8_t)(vli);

  000ee	8a 45 08	 mov	 al, BYTE PTR _vli$[ebp]
  000f1	8b 4d 18	 mov	 ecx, DWORD PTR _out_pos$[ebp]
  000f4	8b 11		 mov	 edx, DWORD PTR [ecx]
  000f6	8b 4d 14	 mov	 ecx, DWORD PTR _out$[ebp]
  000f9	88 04 11	 mov	 BYTE PTR [ecx+edx], al

; 64   : 	++*out_pos;

  000fc	8b 55 18	 mov	 edx, DWORD PTR _out_pos$[ebp]
  000ff	8b 02		 mov	 eax, DWORD PTR [edx]
  00101	83 c0 01	 add	 eax, 1
  00104	8b 4d 18	 mov	 ecx, DWORD PTR _out_pos$[ebp]
  00107	89 01		 mov	 DWORD PTR [ecx], eax

; 65   : 	++*vli_pos;

  00109	8b 55 10	 mov	 edx, DWORD PTR _vli_pos$[ebp]
  0010c	8b 02		 mov	 eax, DWORD PTR [edx]
  0010e	83 c0 01	 add	 eax, 1
  00111	8b 4d 10	 mov	 ecx, DWORD PTR _vli_pos$[ebp]
  00114	89 01		 mov	 DWORD PTR [ecx], eax

; 66   : 
; 67   : 	return vli_pos == &vli_pos_internal ? LZMA_OK : LZMA_STREAM_END;

  00116	8b 55 10	 mov	 edx, DWORD PTR _vli_pos$[ebp]
  00119	8d 45 fc	 lea	 eax, DWORD PTR _vli_pos_internal$[ebp]
  0011c	33 c9		 xor	 ecx, ecx
  0011e	3b d0		 cmp	 edx, eax
  00120	0f 95 c1	 setne	 cl
  00123	8b c1		 mov	 eax, ecx
$LN10@lzma_vli_e:

; 68   : 
; 69   : }

  00125	8b e5		 mov	 esp, ebp
  00127	5d		 pop	 ebp
  00128	c3		 ret	 0
_lzma_vli_encode ENDP
END
